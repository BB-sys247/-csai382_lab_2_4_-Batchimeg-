{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79a293f5-e88b-4970-b59b-75e2a867213e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Notebook Overview"
    }
   },
   "source": [
    "%undefined\n",
    "### Notebook Overview\n",
    "\n",
    "This notebook demonstrates a typical ETL and feature engineering workflow using PySpark and Pandas. It begins by exploring two Bronze tables containing raw device messages and rapid step test results. The notebook then cleans and transforms these datasets, computes summary statistics, and engineers features by joining sensor readings with test windows. Finally, it visualizes sensor data for a sample device and prepares a compact features table suitable for machine learning tasks. Each step is designed to illustrate best practices for data preparation and feature extraction in a modern analytics pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3204420b-5e43-481b-ba0a-a17ef280f14a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Bronze Table Exploration Explanation"
    }
   },
   "source": [
    "%undefined\n",
    "### Bronze Table Exploration\n",
    "\n",
    "This cell loads the raw Bronze tables (`device_messages_raw` and `rapid_step_tests_raw`) and prints their schemas. The purpose is to understand the available fields and data types before any cleaning or transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b79b9d73-6390-4492-9ea4-6ae442fa21ac",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Bronze Table Exploration Explanation"
    }
   },
   "outputs": [],
   "source": [
    "# Spark DataFrames from the catalog\n",
    "\n",
    "dm = spark.table(\"workspace.bronze.device_messages_raw\")\n",
    "\n",
    "rt = spark.table(\"workspace.bronze.rapid_step_tests_raw\")\n",
    "\n",
    "dm.printSchema()\n",
    "\n",
    "rt.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14856261-62fd-4740-8b37-788c1fe0bc75",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Device Message Cleaning Explanation"
    }
   },
   "source": [
    "%undefined\n",
    "### Device Message Cleaning\n",
    "\n",
    "This cell loads raw device messages and performs data cleaning. It extracts numeric distance values, converts them to centimeters, and ensures timestamps are in integer format. The result is a cleaned DataFrame ready for analysis and feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63eca132-2842-400c-a557-27a3aa7cafad",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Device Message Statistics Explanation"
    }
   },
   "source": [
    "%undefined\n",
    "### Device Message Statistics\n",
    "\n",
    "This cell computes summary statistics for each device, including the number of readings, average, minimum, and maximum distance. The result helps identify device activity patterns and potential outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71665347-9189-4c9e-9956-a734a0b32fce",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 3"
    }
   },
   "outputs": [],
   "source": [
    "dm_stats = (dm_clean\n",
    "    .groupBy(\"device_id\")\n",
    "    .agg(F.count(\"*\").alias(\"n\"),\n",
    "         F.avg(\"distance_cm\").alias(\"avg_cm\"),\n",
    "         F.min(\"distance_cm\").alias(\"min_cm\"),\n",
    "         F.max(\"distance_cm\").alias(\"max_cm\"))\n",
    "    .orderBy(F.desc(\"n\"))\n",
    ")\n",
    "display(dm_stats.limit(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba08bdd9-0673-47af-858e-131bc0796111",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Rapid Step Test Feature Engineering Explanation"
    }
   },
   "source": [
    "%undefined\r\n",
    "### Rapid Step Test Feature Engineering\r\n",
    "\r\n",
    "This cell explodes the step points array in the rapid step tests, calculates step timing statistics per test, and displays the results. The purpose is to extract granular step timing features for each test, which are useful for ML modeling and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20ec182b-eded-4978-8de2-6ef974053bdf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 4"
    }
   },
   "outputs": [],
   "source": [
    "rt = spark.table(\"workspace.bronze.rapid_step_tests_raw\")\n",
    "\n",
    "rt_exploded = (rt\n",
    "    .select(\"customer\", \"device_id\", \"start_time\", \"stop_time\", \"test_time\", \"total_steps\", F.posexplode(\"step_points\").alias(\"step_index\", \"step_ms\"))\n",
    ")\n",
    "\n",
    "display(rt_exploded.limit(20))\n",
    "\n",
    "# Step timing stats per test\n",
    "step_stats = (rt_exploded\n",
    "    .groupBy(\"customer\", \"device_id\", \"start_time\", \"stop_time\")\n",
    "    .agg(F.count(\"*\").alias(\"steps\"),\n",
    "         F.avg(\"step_ms\").alias(\"avg_step_ms\"),\n",
    "         F.stddev(\"step_ms\").alias(\"sd_step_ms\"))\n",
    "    .orderBy(F.desc(\"steps\"))\n",
    ")\n",
    "\n",
    "display(step_stats.limit(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6fbfaed7-3968-42a1-bd51-1863313332dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "%undefined\n",
    "### Feature Table Construction\n",
    "\n",
    "This cell joins rapid step test windows with device sensor readings, aggregating summary statistics (count, average, min, max, variance) for each test. The resulting features table is suitable for machine learning training and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "159b78d3-bb4b-4018-b16b-4e13f9c724a4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Device Distance Line Plot Explanation"
    }
   },
   "source": [
    "%undefined\n",
    "### Device Distance Line Plot\n",
    "\n",
    "This cell samples distance readings for one device and plots them over time. The purpose is to visually inspect sensor behavior and identify trends or anomalies in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7216a3b-6e93-44f5-9461-d40e7eaa7020",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 6"
    }
   },
   "outputs": [],
   "source": [
    "# Small sample for a simple line plot of distances over time for one device\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_device = features.select(\"t.device_id\").first()[\"device_id\"]\n",
    "\n",
    "pdf = (dm_clean\n",
    "       .filter(F.col(\"device_id\") == sample_device)\n",
    "       .orderBy(\"ts_ms\")\n",
    "       .limit(1000)\n",
    "       .select(\"ts_ms\", \"distance_cm\")\n",
    "       .toPandas())\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(pdf[\"ts_ms\"], pdf[\"distance_cm\"])\n",
    "plt.title(f\"Distance over time (device {sample_device})\")\n",
    "plt.xlabel(\"timestamp (ms)\")\n",
    "plt.ylabel(\"distance (cm)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7a7b07b-068c-4a57-b50e-bcd40a40766d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Python features table explanation"
    }
   },
   "source": [
    "%undefined\n",
    "This Python section mirrors the SQL steps, but prepares a compact features table (avg/min/max/variance of distance within each test window). We will reuse this features table in ML weeks."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "2_5_Part2_PySpark_Pandas",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
