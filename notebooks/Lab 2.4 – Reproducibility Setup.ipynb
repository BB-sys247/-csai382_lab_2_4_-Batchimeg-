{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a436d5e9-3ee5-448d-b035-020941707402",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 1"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Use absolute paths for file existence check\n",
    "menu_items_path = \"/Workspace/Users/bab045@ensign.edu/-csai382_lab_2_4_-Batchimeg-/data/menu_items.csv\"\n",
    "order_details_path = \"/Workspace/Users/bab045@ensign.edu/-csai382_lab_2_4_-Batchimeg-/data/order_details.csv\"\n",
    "\n",
    "print(\"menu_items.csv exists:\", os.path.exists(menu_items_path))\n",
    "print(\"order_details.csv exists:\", os.path.exists(order_details_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb6405f9-c9e2-4d15-aa26-f641393d60a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd487478-b705-4a3f-89af-5140911e61b9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set random seeds for reproducibility"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "print(\"Random seeds set for reproducibility.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1ebc702-048f-4c52-854b-2cde4b92333b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Compute SHA-256 hashes for CSV files"
    }
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Use absolute paths for hashing\n",
    "csv_files = [\n",
    "    \"/Workspace/Users/bab045@ensign.edu/-csai382_lab_2_4_-Batchimeg-/data/menu_items.csv\",\n",
    "    \"/Workspace/Users/bab045@ensign.edu/-csai382_lab_2_4_-Batchimeg-/data/order_details.csv\"\n",
    "]\n",
    "data_hashes = {}\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    if os.path.exists(csv_file):\n",
    "        with open(csv_file, 'rb') as f:\n",
    "            file_bytes = f.read()\n",
    "            sha256_hash = hashlib.sha256(file_bytes).hexdigest()\n",
    "            data_hashes[os.path.basename(csv_file)] = sha256_hash\n",
    "    else:\n",
    "        data_hashes[os.path.basename(csv_file)] = None\n",
    "        print(f\"File not found: {csv_file}\")\n",
    "\n",
    "# Use a timestamped filename to avoid overwriting\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "filename = f'data_hashes_{timestamp}.json'\n",
    "with open(filename, 'w') as f:\n",
    "    json.dump(data_hashes, f, indent=2)\n",
    "\n",
    "print(f\"SHA-256 hashes computed and saved to {filename}:\")\n",
    "print(json.dumps(data_hashes, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e509eefa-d62b-411c-9cc3-7f5d5a191ddf",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load CSVs from /data into DataFrames"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use absolute paths for loading CSVs\n",
    "menu_items_path = \"/Workspace/Users/bab045@ensign.edu/-csai382_lab_2_4_-Batchimeg-/data/menu_items.csv\"\n",
    "order_details_path = \"/Workspace/Users/bab045@ensign.edu/-csai382_lab_2_4_-Batchimeg-/data/order_details.csv\"\n",
    "\n",
    "try:\n",
    "    menu_items_df = pd.read_csv(menu_items_path)\n",
    "    print(f\"Loaded {menu_items_path} with shape {menu_items_df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load {menu_items_path}: {e}\")\n",
    "    menu_items_df = None\n",
    "\n",
    "try:\n",
    "    order_details_df = pd.read_csv(order_details_path)\n",
    "    print(f\"Loaded {order_details_path} with shape {order_details_df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load {order_details_path}: {e}\")\n",
    "    order_details_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7676239-d7ff-42e3-90ff-0249b231d63d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Clean DataFrames: Dates, Text, Types"
    }
   },
   "outputs": [],
   "source": [
    "def clean_dataframe(df):\r\n",
    "    # Trim whitespace from string columns\r\n",
    "    str_cols = df.select_dtypes(include=['object']).columns\r\n",
    "    for col in str_cols:\r\n",
    "        df[col] = df[col].astype(str).str.strip()\r\n",
    "    # Convert date columns to datetime\r\n",
    "    for col in df.columns:\r\n",
    "        if 'date' in col.lower() or 'time' in col.lower():\r\n",
    "            try:\r\n",
    "                df[col] = pd.to_datetime(df[col], errors='coerce')\r\n",
    "                print(f\"Converted {col} to datetime.\")\r\n",
    "            except Exception as e:\r\n",
    "                print(f\"Could not convert {col} to datetime: {e}\")\r\n",
    "    # Convert numeric columns to appropriate types\r\n",
    "    num_cols = df.select_dtypes(include=['object']).columns\r\n",
    "    for col in num_cols:\r\n",
    "        try:\r\n",
    "            df[col] = pd.to_numeric(df[col], errors='ignore')\r\n",
    "        except Exception:\r\n",
    "            pass\r\n",
    "    return df\r\n",
    "\r\n",
    "if menu_items_df is not None:\r\n",
    "    menu_items_df = clean_dataframe(menu_items_df)\r\n",
    "    print(\"menu_items_df cleaned sample:\")\r\n",
    "    print(menu_items_df.head())\r\n",
    "if order_details_df is not None:\r\n",
    "    order_details_df = clean_dataframe(order_details_df)\r\n",
    "    print(\"order_details_df cleaned sample:\")\r\n",
    "    print(order_details_df.head())\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94da797f-9b1b-44f3-8f01-6cef70476295",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Join menu_items and order_details"
    }
   },
   "outputs": [],
   "source": [
    "# Join menu_items_df and order_details_df on menu_item_id = item_id\n",
    "if menu_items_df is not None and order_details_df is not None:\n",
    "    joined_df = pd.merge(menu_items_df, order_details_df, left_on='menu_item_id', right_on='item_id', how='inner')\n",
    "    print(f\"Joined DataFrame shape: {joined_df.shape}\")\n",
    "    print(\"Joined DataFrame sample:\")\n",
    "    print(joined_df.head())\n",
    "else:\n",
    "    print(\"Cannot join: one or both DataFrames are missing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3cf866f-c42e-4b70-a63f-1e1b302f92d3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Top 5 Items by Order Frequency"
    }
   },
   "outputs": [],
   "source": [
    "if 'joined_df' in locals():\n",
    "    # Top 5 items by order frequency (row count)\n",
    "    top_items = joined_df.groupby(['item_name', 'item_id', 'menu_item_id']).size().sort_values(ascending=False).head(5)\n",
    "    top_items_df = top_items.reset_index(name='order_count')\n",
    "    print(\"Top 5 items by order frequency:\")\n",
    "    print(top_items_df)\n",
    "else:\n",
    "    print(\"joined_df is not defined. Please run the join cell first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25b048d8-0213-4e6a-b50f-14f7881a94cd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Revenue by Category"
    }
   },
   "outputs": [],
   "source": [
    "if 'joined_df' in locals():\n",
    "    # Compute revenue for each row (since no quantity column, assume 1 per row)\n",
    "    joined_df['revenue'] = joined_df['price']\n",
    "    # Group by category and sum revenue\n",
    "    revenue_by_category = joined_df.groupby('category')['revenue'].sum().sort_values(ascending=False)\n",
    "    revenue_by_category_df = revenue_by_category.reset_index()\n",
    "    print(\"Revenue by category:\")\n",
    "    print(revenue_by_category_df)\n",
    "else:\n",
    "    print(\"joined_df is not defined. Please run the join cell first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d604678-0050-4223-80b4-38a15cda4357",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Busiest Hour of Day"
    }
   },
   "outputs": [],
   "source": [
    "if 'joined_df' in locals():\r\n",
    "    # Prefer 'order_time' if available, otherwise use 'order_date'\r\n",
    "    if 'order_time' in joined_df.columns:\r\n",
    "        joined_df['hour'] = pd.to_datetime(joined_df['order_time'], errors='coerce').dt.hour\r\n",
    "    elif 'order_date' in joined_df.columns:\r\n",
    "        joined_df['hour'] = pd.to_datetime(joined_df['order_date'], errors='coerce').dt.hour\r\n",
    "    else:\r\n",
    "        print(\"No time or date column found in joined_df.\")\r\n",
    "        joined_df['hour'] = None\r\n",
    "\r\n",
    "    if joined_df['hour'].notnull().any():\r\n",
    "        busiest_hour = joined_df.groupby('hour').size().sort_values(ascending=False).head(1)\r\n",
    "        busiest_hour_df = busiest_hour.reset_index(name='order_count')\r\n",
    "        print(\"Busiest hour of day:\")\r\n",
    "        print(busiest_hour_df)\r\n",
    "    else:\r\n",
    "        print(\"Could not extract hour information from time/date columns.\")\r\n",
    "else:\r\n",
    "    print(\"joined_df is not defined. Please run the join cell first.\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b38aecfb-6aa4-4aee-a7f1-e9a670e6d46e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save Busiest Hour of Day to CSV"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Output directory and filename (Workspace path)\n",
    "output_dir = '/Workspace/Users/bab045@ensign.edu/-csai382_lab_2_4_-Batchimeg-/notebooks/lab2_4_etl_output_metrics'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "output_path = f'{output_dir}/busiest_hour_of_day_{timestamp}.csv'\n",
    "\n",
    "# Save the DataFrame\n",
    "busiest_hour_df.to_csv(output_path, index=False)\n",
    "print(f\"Busiest hour of day saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a56d92c8-f372-4654-b63f-8aa2dd97fa2b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save Revenue by Category to CSV"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Output directory and filename (Workspace path)\n",
    "output_dir = '/Workspace/Users/bab045@ensign.edu/-csai382_lab_2_4_-Batchimeg-/notebooks/lab2_4_etl_output_metrics'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "output_path = f'{output_dir}/revenue_by_category_{timestamp}.csv'\n",
    "\n",
    "# Save the DataFrame\n",
    "revenue_by_category_df.to_csv(output_path, index=False)\n",
    "print(f\"Revenue by category saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9725c6ab-c164-48f8-9094-d02ea46c4bdb",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save Top 5 Items by Order Frequency to CSV"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Output directory and filename (Workspace path)\n",
    "output_dir = '/Workspace/Users/bab045@ensign.edu/-csai382_lab_2_4_-Batchimeg-/notebooks/lab2_4_etl_output_metrics'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "output_path = f'{output_dir}/top_5_items_by_order_frequency_{timestamp}.csv'\n",
    "\n",
    "# Save the DataFrame\n",
    "if 'top_items_df' in locals() and not top_items_df.empty:\n",
    "    top_items_df.to_csv(output_path, index=False)\n",
    "    print(f\"Top 5 items by order frequency saved to {output_path}\")\n",
    "else:\n",
    "    print(\"top_items_df is not defined or empty. Please run the metric cell first.\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Lab 2.4 â€“ Reproducibility Setup",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
