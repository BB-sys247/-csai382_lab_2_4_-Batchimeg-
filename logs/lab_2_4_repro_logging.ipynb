{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e98b9a5d-4322-4ed9-9e72-9d7a1e552cba",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Reproducibility Setup"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74608aea-702e-4a37-a36f-e642fa97d97c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Capture Environment"
    }
   },
   "outputs": [],
   "source": [
    "%pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1028139a-53aa-4ec2-b0b1-e1508653d1f5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 1"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import platform\n",
    "import os\n",
    "from datetime import datetime\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Prepare log file name with current timestamp\n",
    "now = datetime.now()\n",
    "log_dir = \"logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "base_filename = f\"run_{now.strftime('%Y%m%d_%H%M')}.log\"\n",
    "log_filename = f\"{log_dir}/{base_filename}\"\n",
    "\n",
    "# If file exists, append a random suffix\n",
    "if os.path.exists(log_filename):\n",
    "    suffix = ''.join(random.choices(string.ascii_lowercase + string.digits, k=6))\n",
    "    log_filename = f\"{log_dir}/run_{now.strftime('%Y%m%d_%H%M')}_{suffix}.log\"\n",
    "\n",
    "log_format = '%(asctime)s | %(levelname)s | %(message)s'\n",
    "logging.basicConfig(level=logging.INFO, format=log_format)\n",
    "\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "console_handler.setFormatter(logging.Formatter(log_format))\n",
    "\n",
    "file_handler = logging.FileHandler(log_filename)\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(logging.Formatter(log_format))\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.handlers.clear()  # Clear existing handlers\n",
    "logger.addHandler(console_handler)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Log the start of the run\n",
    "logger.info(\"Run started at %s\", now.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# Log cluster/runtime info\n",
    "logger.info(f\"Python version: {sys.version}\")\n",
    "logger.info(f\"Platform: {platform.platform()}\")\n",
    "logger.info(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Log configuration values\n",
    "logger.info(f\"Log level: INFO\")\n",
    "logger.info(f\"Log format: {log_format}\")\n",
    "logger.info(f\"Log file: {log_filename}\")\n",
    "\n",
    "logger.info(\"Hello World\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be2cb4e6-7029-426a-9352-e8e67d723238",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save Data Hashes to JSON"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "hashes = {}\n",
    "try:\n",
    "    hashes['menu_items.csv'] = compute_sha256(menu_items_path)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to hash {menu_items_path}: {e}\")\n",
    "    hashes['menu_items.csv'] = None\n",
    "try:\n",
    "    hashes['order_details.csv'] = compute_sha256(order_details_path)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to hash {order_details_path}: {e}\")\n",
    "    hashes['order_details.csv'] = None\n",
    "\n",
    "with open('data_hashes.json', 'w') as f:\n",
    "    json.dump(hashes, f, indent=2)\n",
    "logger.info(f\"Saved data hashes to data_hashes.json: {hashes}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "167edf64-f5dd-4af3-a353-182d56dd47fd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Ethics Section for README.md"
    }
   },
   "source": [
    "%undefined\n",
    "### Ethics Statement\n",
    "\n",
    "* We commit to responsible data use, ensuring privacy and security for all customer and business information.\n",
    "* All data processing follows legal and ethical guidelines, with transparency in data handling and reporting.\n",
    "* We avoid bias in analysis and respect the rights of individuals represented in the data.\n",
    "* Data is used solely for educational and improvement purposes, not for commercial exploitation.\n",
    "* Any sensitive information is anonymized or protected according to best practices.\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "lab_2_4_repro_logging",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
